{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659919e2",
   "metadata": {},
   "source": [
    "# Star Trek Uniform Classifier - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd79aad",
   "metadata": {},
   "source": [
    "* Collect images of Star Trek uniforms\n",
    "    * Red, Blue, Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e008b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D # to add convolutional layers\n",
    "from keras.layers import MaxPooling2D # to add pooling layers\n",
    "from keras.layers import Flatten # to flatten data for fully connected layers\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2e9da",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7cb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data path and categories\n",
    "data_dir = Path('rawData')\n",
    "categories = ['commandRed', 'scienceBlue', 'operationGold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27023707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to handle images\n",
    "def clean_and_verify_data(base_path, folder_list):\n",
    "\n",
    "    # iterate through categires\n",
    "    for category in folder_list:\n",
    "        path = base_path / category\n",
    "        print(f\"==== Checking for: {category} ====\")\n",
    "\n",
    "        files = list(path.glob('*'))\n",
    "        for file_path in files:\n",
    "            # remove everything except jpg, jpeg and png\n",
    "            if file_path.suffix.lower() not in ['.jpg', '.jpeg', '.png']:\n",
    "                print(f\"Revoming: {file_path.name}\")\n",
    "                file_path.unlink()\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # try open img to check for corruption\n",
    "                with Image.open(file_path) as img:\n",
    "                    img.verify() # verify whether its img\n",
    "\n",
    "                # convert to RBG in case more channels\n",
    "                with Image.open(file_path) as img:\n",
    "                    img = img.convert('RGB')\n",
    "                    img = img.resize((128, 128)) # resize img \n",
    "                    img.save(file_path) # overwrite !!\n",
    "\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Deleting file: {file_path.name}\")\n",
    "                file_path.unlink()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f103a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_and_verify_data(data_dir, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f7d2d",
   "metadata": {},
   "source": [
    "# Normalize data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "# constants\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# load and split\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    'rawData',\n",
    "    validation_split=0.2, # 20% for testing\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    'rawData',\n",
    "    validation_split=0.2, # 20% for validation\n",
    "    subset='validation',\n",
    "    seed=42,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# save classes name for debug\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Classes found: {class_names}\")\n",
    "\n",
    "# normalize\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "# apply to dataset\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9161c",
   "metadata": {},
   "source": [
    "# Veryfing if data is GOOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb7fd4",
   "metadata": {},
   "source": [
    "## Visual verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# take one batch from ds\n",
    "for images, labels in train_ds.take(1):\n",
    "    # images is a tensor of shape (32, 128, 128, 3)\n",
    "    # labels is a tensor of shape (32, 3)\n",
    "    \n",
    "    first_image = images[0].numpy()\n",
    "    first_label = labels[0].numpy()\n",
    "    \n",
    "    plt.imshow(first_image)\n",
    "    plt.title(f\"Label: {class_names[np.argmax(first_label)]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # print pixel range (max should be 1 and min should be 0)\n",
    "    print(f\"Max pixel value: {np.max(first_image)}\")\n",
    "    print(f\"Min pixel value: {np.min(first_image)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8091b0af",
   "metadata": {},
   "source": [
    "## Shape verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"Image batch shape: {images.shape}\") # expect (32, 128, 128, 3), batch size, height, widht, channel numb RGB\n",
    "    print(f\"Label batch shape: {labels.shape}\") # expect (32, 3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f293dba",
   "metadata": {},
   "source": [
    "## Class balance verification - after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in class_names:\n",
    "    path = f'rawData/{category}'\n",
    "    print(f\"{category}: {len(os.listdir(path))} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb41bf3",
   "metadata": {},
   "source": [
    "* operationGold is a bit smaller. **NEED TO AUGMENTATION** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35fc6c",
   "metadata": {},
   "source": [
    "## Normalization check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(f\"Data type: {images.dtype}\") \n",
    "    print(f\"First pixel value: {images[0, 0, 0, 0].numpy()}\")\n",
    "# expect float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc65d537",
   "metadata": {},
   "source": [
    "# Building Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91ad7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "\n",
    "# augmentation\n",
    "data_augmentation = Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1)\n",
    "])\n",
    "\n",
    "def star_trek_cnn_model():\n",
    "    '''\n",
    "    input\n",
    "    3 Conv2D / Maxpooling layers; relu\n",
    "    flatten\n",
    "    dense; relu\n",
    "    regularization\n",
    "    output, dense; softmax to probabilities\n",
    "    '''\n",
    "    model = keras.Sequential([\n",
    "        # input\n",
    "        layers.Input(shape=(128, 128, 3)),\n",
    "        data_augmentation,\n",
    "\n",
    "        # first layer, edges\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # second layer, shapes\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # third layer, complex patterns\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "        # output layer\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init and run model\n",
    "custom_model = star_trek_cnn_model()\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c2b350",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = custom_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=25,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54232e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = custom_model.evaluate(val_ds, verbose=0)\n",
    "print(f\"Test Accuracy: {scores[1]:.4f}\")\n",
    "print(f\"Test Loss: {scores[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5c6d9",
   "metadata": {},
   "source": [
    "## Confusion matrix x Loss curve graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51197d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fd12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(model, dataset, class_names):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # iterate through dataset\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images, verbose=0)\n",
    "        \n",
    "        # handle ondehotencode and sparselabelss\n",
    "        if len(labels.shape) > 1 and labels.shape[1] > 1:\n",
    "            y_true.extend(np.argmax(labels, axis=1))\n",
    "        else:\n",
    "            y_true.extend(labels.numpy())\n",
    "            \n",
    "        y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # conf matrx\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='magma', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.title('Confusion Matrix: Model Performance Evaluation', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    # scientific matrics\n",
    "    print(\"\\n--- CLASSIFICATION REPORT ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(custom_model, val_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b613fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6182a6e",
   "metadata": {},
   "source": [
    "# Using a pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_weights_path = 'mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a631559b",
   "metadata": {},
   "source": [
    "## Trying MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "base_model = keras.applications.MobileNetV2(\n",
    "    weights=local_weights_path,\n",
    "    input_shape=(128, 128, 3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "# freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "mobilenet_model = keras.Sequential([\n",
    "    layers.Input(shape=(128, 128, 3)),\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(), # flatten 3D data into 1D\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(3, activation='softmax') \n",
    "])\n",
    "\n",
    "mobilenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train again\n",
    "history_transfer = mobilenet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28558579",
   "metadata": {},
   "source": [
    "* worse than model built from scratch\n",
    "    * need to unfreeze small bit of pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41797b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# print(f\"Number of layers in base model: {len(base_model.layers)}\")\n",
    "# base model has 154 layers\n",
    "\n",
    "fine_tune_at = 130 # freeze everything except the last 20 layers\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# recompile // low learning rate\n",
    "mobilenet_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7906a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 15\n",
    "total_epochs = 20 + fine_tune_epochs\n",
    "\n",
    "history_fine_tune = mobilenet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history_transfer.epoch[-1], # start from left off\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce435aa",
   "metadata": {},
   "source": [
    "* Accuracy 90%\n",
    "* Validation accuracy 75%\n",
    "* overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1119396",
   "metadata": {},
   "source": [
    "* Model is memorizing = overfitting. Training loss decrease while Validation loss increases\n",
    "* \"commandRed\" class precision is 0.53\n",
    "* scienceBlue f1-score is 0.61\n",
    "* the model guessed commandRed for 39 instances of that actually were scienceBlue\n",
    "-----\n",
    "* increase dropout\n",
    "* L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38175912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "# make the images change to avoid memorizing\n",
    "data_augmentation.add(layers.RandomContrast(0.2))\n",
    "\n",
    "# update final layers\n",
    "mobilenet_model = keras.Sequential([\n",
    "    layers.Input(shape=(128, 128, 3)),\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re compile\n",
    "mobilenet_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001), \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# early stop callback. If val loss do not \n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Red: 410, Gold: 278, Blue: 396\n",
    "total = 410 + 278 + 396\n",
    "class_weight = {\n",
    "    0: (1 / 410) * (total / 3.0), # red\n",
    "    1: (1 / 278) * (total / 3.0), # gold\n",
    "    2: (1 / 396) * (total / 3.0)  # blue\n",
    "}\n",
    "\n",
    "# fit with updated callback and weight\n",
    "history_final = mobilenet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50, \n",
    "    class_weight=class_weight, \n",
    "    callbacks=[early_stop],    \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(mobilenet_model, val_ds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_fine_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b53a9",
   "metadata": {},
   "source": [
    "## Trying EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e7c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_raw = keras.utils.image_dataset_from_directory(\n",
    "    'rawData',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds_raw = keras.utils.image_dataset_from_directory(\n",
    "    'rawData',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b04708",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.EfficientNetB0(\n",
    "    weights='imagenet',\n",
    "    input_shape=(128,128,3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "# freeze\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fca940",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build model\n",
    "efficientnet_model = keras.Sequential([\n",
    "    layers.Input(shape=(128, 128, 3)),\n",
    "    data_augmentation,\n",
    "    layers.GaussianNoise(0.1), # Add random static to the image\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(64, activation='relu'), # Smaller dense layer = less capacity to memorize\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# freeze\n",
    "base_model.trainable = False\n",
    "\n",
    "# re compile\n",
    "efficientnet_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.F1Score(average='macro')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7788e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training again\n",
    "history_eff = efficientnet_model.fit(\n",
    "    train_ds_raw,\n",
    "    validation_data=val_ds_raw,\n",
    "    epochs=15,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[early_stop], # early stopping from before\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c99084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze base model\n",
    "base_model.trainable = True\n",
    "\n",
    "fine_tune_at = 188 # freeze everything except the last 50 layers\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# recompile // low learning rate\n",
    "efficientnet_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_eff_epochs = 15\n",
    "total_epochs = 20 + history_eff_epochs\n",
    "\n",
    "history_enb0 = efficientnet_model.fit(\n",
    "    train_ds_raw,\n",
    "    validation_data=val_ds_raw,\n",
    "    epochs=total_epochs,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[early_stop],\n",
    "    initial_epoch=history_eff.epoch[-1], # start from left off\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(efficientnet_model, val_ds_raw, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ed05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_enb0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8da93",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588092a1",
   "metadata": {},
   "source": [
    "---\n",
    "* Scratch Model\n",
    "    * accuracy: 0.8921 || 89%\n",
    "    * loss: 0.2779 || 27%\n",
    "    * val_accuracy: 0.8981 || 89%\n",
    "    * val_loss: 0.3372 || 33%\n",
    "* MobileNetV2\n",
    "    * accuracy: 0.9063 || 90%\n",
    "    * loss: 0.2612 || 26%\n",
    "    * val_accuracy: 0.7580 || 75%\n",
    "    * val_loss: 0.6910 || 69%\n",
    "* EfficientNetB0\n",
    "    * accuracy: 0.7079 || 70%\n",
    "    * loss: 0.6972 || 69%\n",
    "    * val_accuracy: 0.7452 || 74%\n",
    "    * val_loss: 0.6973 || 69%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b611f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "DATA_DIR = 'rawData'\n",
    "\n",
    "# --- DATA COLLECTION ---\n",
    "file_paths = []\n",
    "labels = []\n",
    "class_names = sorted([f for f in os.listdir(DATA_DIR) if not f.startswith('.')])\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_path = os.path.join(DATA_DIR, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = [os.path.join(class_path, f) for f in os.listdir(class_path) if not f.startswith('.')]\n",
    "        file_paths.extend(images)\n",
    "        labels.extend([i] * len(images))\n",
    "\n",
    "file_paths = np.array(file_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# --- HELPER: DATASET GENERATOR ---\n",
    "def get_dataset(paths, labels_int):\n",
    "    # convert int labels to categorical for softmax output\n",
    "    labels_cat = tf.keras.utils.to_categorical(labels_int, num_classes=3)\n",
    "    \n",
    "    def _parse_image(path, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = img / 255.0  # scale - onrmalized\n",
    "        return img, label\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels_cat))\n",
    "    ds = ds.map(_parse_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# --- K-FOLD LOOP ---\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(file_paths, labels)):\n",
    "    print(f\"\\n fold {fold+1}/5\")\n",
    "    \n",
    "    train_ds = get_dataset(file_paths[train_idx], labels[train_idx])\n",
    "    val_ds = get_dataset(file_paths[val_idx], labels[val_idx])\n",
    "    \n",
    "    # re init to clear weights\n",
    "    model = star_trek_cnn_model() \n",
    "    \n",
    "    # prevent overfit earlystop\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=30, verbose=0, callbacks=[early_stop])\n",
    "    \n",
    "    _, acc = model.evaluate(val_ds, verbose=0)\n",
    "    fold_results.append(acc)\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# --- SUMMARY ---\n",
    "print(f\"\\n--- SUMMARY ---\")\n",
    "print(f\"Mean Accuracy: {np.mean(fold_results)*100:.2f}%\")\n",
    "print(f\"Standard Deviation: {np.std(fold_results)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b086dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
